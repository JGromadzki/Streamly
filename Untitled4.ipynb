{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxo+b9iZQxn/SoHanxAJp2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JGromadzki/Streamly/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit\n",
        "pip install groq\n",
        "pip install langchain\n",
        "pip install langchain_groq\n",
        "pip install --upgrade pip\n",
        "pip install git+https://github.com/theskumar/python-dotenv.git\n",
        "\n",
        "\n",
        "import streamlit as st\n",
        "import os\n",
        "from groq import Groq\n",
        "import random\n",
        "\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.prompts import PromptTemplate\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Set the environment variable\n",
        "os.environ['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'] = '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'\n",
        "\n",
        "# Access the environment variable\n",
        "groq_api_key = os.environ['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']\n",
        "\n",
        "def main():\n",
        "\n",
        "    st.title(\"Groq Chat App\")\n",
        "\n",
        "    # Add customization options to the sidebar\n",
        "    st.sidebar.title('Select an LLM')\n",
        "    model = st.sidebar.selectbox(\n",
        "        'Choose a model',\n",
        "        ['mixtral-8x7b-32768', 'llama2-70b-4096']\n",
        "    )\n",
        "    conversational_memory_length = st.sidebar.slider('Conversational memory length:', 1, 10, value = 5)\n",
        "\n",
        "    memory=ConversationBufferWindowMemory(k=conversational_memory_length)\n",
        "\n",
        "    user_question = st.text_area(\"Ask a question:\")\n",
        "\n",
        "    # session state variable\n",
        "    if 'chat_history' not in st.session_state:\n",
        "        st.session_state.chat_history=[]\n",
        "    else:\n",
        "        for message in st.session_state.chat_history:\n",
        "            memory.save_context({'input':message['human']},{'output':message['AI']})\n",
        "\n",
        "\n",
        "    # Initialize Groq Langchain chat object and conversation\n",
        "    groq_chat = ChatGroq(\n",
        "            groq_api_key=groq_api_key,\n",
        "            model_name=model\n",
        "    )\n",
        "\n",
        "    conversation = ConversationChain(\n",
        "            llm=groq_chat,\n",
        "            memory=memory\n",
        "    )\n",
        "\n",
        "    if user_question:\n",
        "        response = conversation(user_question)\n",
        "        message = {'human':user_question,'AI':response['response']}\n",
        "        st.session_state.chat_history.append(message)\n",
        "        st.write(\"Chatbot:\", response['response'])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "j8ewA_-KWUlM"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}